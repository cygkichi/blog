from dotenv import load_dotenv
load_dotenv(verbose=True)

import streamlit as st

import operator
from typing import TypedDict, Annotated, Sequence

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import BaseMessage,HumanMessage,AIMessage
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import WikipediaLoader

from langgraph.graph import StateGraph, END


# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
model = ChatOpenAI(model_name='gpt-4-turbo')
# model = ChatOpenAI(model_name='gpt-3.5-turbo')

class AgentState(TypedDict):
    user_question : str #ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
    messages: Annotated[Sequence[BaseMessage], operator.add] #ä¼šè©±å±¥æ­´
    knowledge_base : Annotated[str, operator.add] #çŸ¥è­˜ãƒ™ãƒ¼ã‚¹(æ¤œç´¢ã—ãŸæƒ…å ±ã‚’è¿½è¨˜ã—ã¦ã„ã)
    next_task_search_keyword : str #æ¬¡ã«æ¤œç´¢ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    next_task_search_content : str #æ¬¡ã«æ¤œç´¢ã—ã¦èª¿ã¹ã‚‹å†…å®¹
    answer_counter : Annotated[int, operator.add] #æœ€çµ‚å›ç­”ã‚’è©¦ã¿ãŸå›æ•°


def call_init_agentstate(state):
    state["user_question"] = state['messages'][-1].content
    state["messages"] = []
    state["knowledge_base"] = ""
    state["answer_counter"] = 0
    return state

from langchain.output_parsers import PydanticOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field, validator

class SearchTask(BaseModel):
    search_reason: str = Field(description="æ¤œç´¢ã™ã‚‹ç†ç”±ã‚„ç›®çš„ã€‚")
    search_keyword: str = Field(description="Wikipediaã§ã®æ¤œç´¢ã™ã‚‹å˜èªã€‚å¿…ãšã²ã¨ã¤ã®å˜èªã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚")
    search_content : str = Field(description="æ¤œç´¢ã—ãŸWikipediaã®ãƒšãƒ¼ã‚¸ã§å–å¾—ã—ãŸã„æƒ…å ±ã€‚")

gen_task_template ="""
ä»¥ä¸‹ã®è³ªå•ã«å›ç­”ã™ã‚‹ãŸã‚ã€ä¸è¶³ã—ã¦ã„ã‚‹æƒ…å ±ã‚’wikipediaã‹ã‚‰æ¤œç´¢ã—ã¾ã™ã€‚
æ¤œç´¢ã™ã‚‹æƒ…å ±ã¯æœ€å°ã®ä¸€ã¤ã ã‘ã§ã™ã€‚æ¤œç´¢ã™ã‚‹ãŸã‚ã®å˜èªã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
æ¤œç´¢ã™ã‚‹é …ç›®ã‚„ãã®ç†ç”±ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
æ¤œç´¢ã™ã‚‹é …ç›®ã¯ä¸€ã¤ã ã‘ã§ã™ã€‚
è¤‡æ•°ã®è³ªå•ãŒãªã•ã‚Œã¦ã„ã¦ã‚‚ã€ä¸€ã¤ã®è³ªå•ã«å¯¾ã—ã¦ã®ã¿å›ç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

{format_instructions}

-----------------
è³ªå•ä¾‹:æ˜ ç”»ã‚ªãƒƒãƒšãƒ³ãƒã‚¤ãƒãƒ¼ã®ç›£ç£ãŒä½œæˆã—ãŸæ˜ ç”»ã®æœ¬æ•°ã‚’èª¿ã¹ã¦ãã ã•ã„ã€‚
search_reason="æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€‚ã¨ã‚Šã‚ãˆãšã¾ãš"æ˜ ç”»ã‚ªãƒƒãƒšãƒ³ãƒã‚¤ãƒãƒ¼"ã®wikipediaã‚’æ¤œç´¢ã—ã¦ã€ç›£ç£ã®åå‰ã‚’èª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
search_keyword="ã‚ªãƒƒãƒšãƒ³ãƒã‚¤ãƒãƒ¼"
search_content="æ˜ ç”»ã‚ªãƒƒãƒšãƒ³ãƒã‚¤ãƒãƒ¼ã®ç›£ç£ã®åå‰"
-----------------
è³ªå•ä¾‹:ä¸­æ€§å­ã¨åŸå­æ ¸ãŒç™ºè¦‹ã•ã‚ŒãŸå¹´ã«èµ·ã“ã£ãŸå‡ºæ¥äº‹ã‚’èª¿ã¹ã¦ãã ã•ã„ã€‚
search_reason="æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€ã¨ã‚Šã‚ãˆãšã¾ãš"ä¸­æ€§å­"ã®wikipediaã‚’æ¤œç´¢ã—ã¦ã€ã¨ã‚Šã‚ãˆãšç™ºè¦‹ã•ã‚ŒãŸå¹´ã‚’èª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
search_keyword="ä¸­æ€§å­"
search_content="ä¸­æ€§å­ã®ç™ºè¦‹ã•ã‚ŒãŸå¹´"
-----------------
è³ªå•ä¾‹:ä¸­æ€§å­ã¨åŸå­æ ¸ãŒç™ºè¦‹ã•ã‚ŒãŸå¹´ã«èµ·ã“ã£ãŸå‡ºæ¥äº‹ã‚’èª¿ã¹ã¦ãã ã•ã„ã€‚ãŸã ã—ã€ä»¥ä¸‹ã®æƒ…å ±ã¯ã™ã§ã«æ¤œç´¢æ¸ˆã¿ã§ã™ã€‚ä¸­æ€§å­ã®ç™ºè¦‹ã•ã‚ŒãŸå¹´ã¯1932å¹´ã§ã™ã€‚
search_reason="åŸå­æ ¸ã«é–¢ã™ã‚‹æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã€"åŸå­æ ¸"ã®wikipediaã‚’æ¤œç´¢ã—ã¦ã€ç™ºè¦‹ã•ã‚ŒãŸå¹´ã‚’èª¿ã¹ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
search_keyword="åŸå­æ ¸"
search_content="åŸå­æ ¸ã®ç™ºè¦‹ã•ã‚ŒãŸå¹´"
-----------------

è³ªå•:{user_question}ã€‚{knowledge_base}
"""
def call_generate_task(state):
    _parser = PydanticOutputParser(pydantic_object=SearchTask)
    _prompt = PromptTemplate(
        template=gen_task_template,
        input_variables=["user_question", "knowledge_base"],
        partial_variables={"format_instructions": _parser.get_format_instructions()},
    )
    chain = _prompt| model | _parser
    # chain = chain.with_retry(stop_after_attempt=5)
    res = chain.invoke({'user_question': state['user_question'], 'knowledge_base': state['knowledge_base']})

    return {
        "messages": [AIMessage(content=res.search_reason)],
        'next_task_search_keyword':res.search_keyword,
        'next_task_search_content':res.search_content
    }

def search_for_wikipedia(query: str) -> str:
    """
    Search for a wikipedia article and return the content of the first article found.
    """
    docs = WikipediaLoader(query=query, load_max_docs=5, lang='ja').load()
    if len(docs) > 0:
        return ''.join([d.page_content for d in docs])
    return ""


search_and_answer_template ="""
ä»¥ä¸‹ã®å‚è€ƒæ–‡æ›¸ã‚’ä½¿ç”¨ã—ã¦ã€çŸ¥ã‚ŠãŸã„å†…å®¹ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
çŸ¥ã‚ŠãŸã„å†…å®¹ã«ã¯ç°¡æ½”ã«æ•°10æ–‡å­—ã®ãƒ†ã‚­ã‚¹ãƒˆã§ç­”ãˆã¦ãã ã•ã„ã€‚
ãŸã¨ãˆã°ã€ã€ŒXXXã¯YYYã§ã™ã€‚ã€ã¨çŸ­æ–‡ã§å›ç­”ã™ã‚‹ã“ã¨ã€‚

ä¸è¦ãªæƒ…å ±ã¯å‰Šé™¤ã™ã‚‹ã“ã¨ã€‚

å‚è€ƒæ–‡æ›¸:{searched_content}

çŸ¥ã‚ŠãŸã„å†…å®¹:{next_task_search_content}
"""

def call_search_and_answer(state):
    searched_content = search_for_wikipedia(state['next_task_search_keyword'])

    _parser = PydanticOutputParser(pydantic_object=SearchTask)
    _prompt = PromptTemplate(
        template=search_and_answer_template,
        input_variables=["next_task_search_content", "searched_content"],
    )
    chain = _prompt| model | StrOutputParser()

    res = chain.invoke({'next_task_search_content': state['next_task_search_content'], 'searched_content': searched_content})
    new_knowledge = f"æ¤œç´¢ã—ãŸçµæœã€Œ{state['next_task_search_content']}ã€ã«é–¢ã™ã‚‹æƒ…å ±ã¯æ¬¡ã®é€šã‚Šã€‚\n{res}\n\n\n"
    return {
        "messages": [AIMessage(content=new_knowledge)],
        'knowledge_base':new_knowledge,
    }

final_answer ="""
ä»¥ä¸‹ã®çŸ¥è­˜ã‚’ã‚‚ã¨ã«è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
ã‚‚ã—å›ç­”ã«å¿…è¦ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã€å›ç­”ã§ããªç†ç”±ã‚’è¿°ã¹ãŸå¾Œã€ã€Œå›ç­”ä¸å¯ã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚


çŸ¥è­˜:{knowledge_base}

è³ªå•:{user_question}
"""
def call_final_answer(state):
    prompt = ChatPromptTemplate.from_template(template=final_answer)
    chain = prompt| model | StrOutputParser()
    res = chain.invoke({
        'user_question': state['user_question'],
        'knowledge_base': state['knowledge_base']
    })
    return {"messages": [AIMessage(content=res)], "answer_counter":1}

def router_fa(state):
    res = call_final_answer(state)
    if state['answer_counter'] >= 5:
        # print('å›ç­”åˆ¶é™')
        return 'end'
    if 'å›ç­”ä¸å¯' in res['messages'][-1].content:
        return 'continue'
    else:
        return 'end'
    
def get_runnable():
    workflow = StateGraph(AgentState)
    workflow.add_node("init_agent",call_init_agentstate)
    workflow.add_node("generate_task", call_generate_task)
    workflow.add_node("search_and_answer", call_search_and_answer)
    workflow.add_node("final_answer", call_final_answer)

    workflow.set_entry_point("init_agent")
    workflow.add_edge("init_agent", "generate_task")
    workflow.add_edge("generate_task", "search_and_answer")
    workflow.add_edge("search_and_answer", "final_answer")
    workflow.add_conditional_edges(
        "final_answer",
        router_fa,
        {
            "end": END,
            "continue": "generate_task"
        }
    )
    runnable = workflow.compile()
    return runnable

# ------------------------------------------- # -------------------------------------------
# ------------------------------------------- # -------------------------------------------
# ------------------------------------------- # -------------------------------------------
# ------------------------------------------- # -------------------------------------------
st.set_page_config(
    page_title="LangChain: Chat with search",
    page_icon="ğŸ¦œ",
    layout="wide", 
    initial_sidebar_state="auto"
)

st.title("ğŸ¦œğŸ•¸ï¸ LangGraph Agent: Chat with Wikipedia Search")



if "messages" not in st.session_state:
    st.session_state["messages"] = []

col1, col2 = st.columns(spec=[0.8,0.2])

with col1:
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

with col2:
    st.markdown(f"### çŸ¥è­˜ãƒ™ãƒ¼ã‚¹")


if prompt := st.chat_input():
    runnable = get_runnable()
    inputs = {"messages": [HumanMessage(content=prompt)]}
    with col1:
        st.chat_message("user").write(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

    for output in runnable.stream(inputs):
        for key, value in output.items():
            if key == 'init_agent':
                response = f'{key}:ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çŠ¶æ…‹ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚'
            else:
                response = f'{key}:' + value['messages'][-1].content
            avatar  = {
                'init_agent': 'ğŸ¦œ',
                'generate_task': 'ğŸ“œ',
                'search_and_answer': 'ğŸ”',
                'final_answer': 'ğŸ¤–',
            }[key]
            with col1:
                st.chat_message(name=key,avatar =avatar ).write(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            
            with col2:
                new_knowledge_base = value.get('knowledge_base')
                if new_knowledge_base is not None:
                    st.markdown(f"* {new_knowledge_base}")