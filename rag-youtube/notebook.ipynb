{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['OPENAI_API_KEY'] = 'your-api-key'\n",
    "#os.environ['YOUTUBE_API_KEY'] = 'your-api-key'\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 01.Youtubeの動画URLリストを取得する。\n",
    "\n",
    " * apikeyの取得\n",
    "   * https://developers.google.com/youtube/v3/getting-started?hl=ja\n",
    " * 参考:YouTube Data APIを使ってチャンネルに含まれる動画を取得する流れ\n",
    "    * https://zenn.dev/yorifuji/articles/youtube-data-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APIキーをセットします\n",
    "import os\n",
    "import pandas as pd\n",
    "from apiclient.discovery import build\n",
    "YOUTUBE_API_KEY = os.getenv('YOUTUBE_API_KEY')\n",
    "youtube = build('youtube', 'v3', developerKey=YOUTUBE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "チャンネルを検索する。\n",
    "'''\n",
    "channel_search_query = '山田五郎' #'山田五郎' #'高須幹弥' #'ゆる言語学ラジオ'\n",
    "\n",
    "res = youtube.search().list(\n",
    "    part='snippet',\n",
    "    q=channel_search_query,\n",
    "    type= 'channel', #'playlist',\n",
    "    maxResults=10\n",
    ").execute()\n",
    "\n",
    "channel_df = (\n",
    "    pd.DataFrame([\n",
    "        {\n",
    "            'channelTitle': x['snippet']['channelTitle'],\n",
    "            'channelId' : x['snippet']['channelId'],\n",
    "            # 'playlistTitle': x['snippet']['title'],\n",
    "            # 'playlistId': x['id']['playlistId'],\n",
    "\n",
    "        }\n",
    "        for x in res['items']\n",
    "    ])\n",
    ")\n",
    "display(channel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "検索したチャンネルから、オリジナルチャンネルのIDを調べるため、登録者数でソートする。\n",
    "'''\n",
    "records = []\n",
    "for _, row in channel_df.iterrows():\n",
    "    res = youtube.channels().list(\n",
    "        part='snippet,contentDetails,statistics',\n",
    "        id=row['channelId'],\n",
    "        maxResults=1\n",
    "    ).execute()\n",
    "    record = {\n",
    "        'channelId': row['channelId'],\n",
    "        'description' : res['items'][0]['snippet']['localized']['description'],\n",
    "        'subscriberCount' : int(res['items'][0]['statistics']['subscriberCount']),\n",
    "        'videoCount' : int(res['items'][0]['statistics']['videoCount']),\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "channel_df=(\n",
    "    channel_df\n",
    "    .merge(pd.DataFrame(records), on='channelId')\n",
    "    .sort_values('subscriberCount', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "display(channel_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "オリジナルチャンネルの情報\n",
    " * 動画数は257本、登録者数は58万人らしい\n",
    "'''\n",
    "orginal_channel_row = channel_df.iloc[0]\n",
    "orginal_channel_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "動画URLを取得する\n",
    "'''\n",
    "target_channelId = orginal_channel_row['channelId']\n",
    "maxVideos = 500\n",
    "\n",
    "records = []\n",
    "nextPageToken=None\n",
    "while len(records) < maxVideos:\n",
    "    res = youtube.search().list(\n",
    "        pageToken=nextPageToken,\n",
    "        part='snippet',\n",
    "        channelId=target_channelId,\n",
    "        maxResults=50,\n",
    "        type= 'video',\n",
    "        # videoDuration = 'any' # 'short' 'medium' 'long'\n",
    "    ).execute()\n",
    "\n",
    "    nextPageToken = res.get('nextPageToken')\n",
    "    records += [\n",
    "        {\n",
    "            'channelId': target_channelId,\n",
    "            'videoId': x['id']['videoId'],\n",
    "            'videoTitle': x['snippet']['title'],\n",
    "            'videoDescription': x['snippet']['description'],\n",
    "            'videoPublishTime': x['snippet']['publishedAt'],\n",
    "        }\n",
    "        for x in res['items']\n",
    "    ]\n",
    "    print(len(records), nextPageToken)\n",
    "    if nextPageToken is None:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "動画URLを保存する\n",
    "'''\n",
    "video_df = (\n",
    "    pd.DataFrame(records)\n",
    "    .assign(videoPublishTime = lambda x: pd.to_datetime(x['videoPublishTime']))\n",
    "    .sort_values('videoPublishTime', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    "    .rename(columns={\n",
    "        'channelId': 'channel_id',\n",
    "        'videoId': 'video_id',\n",
    "        'videoTitle': 'video_title',\n",
    "        'videoDescription': 'video_description',\n",
    "        'videoPublishTime': 'video_publish_time',\n",
    "    })\n",
    ")\n",
    "video_df.to_csv('video_df.csv', index=False, encoding='utf-8-sig')\n",
    "video_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 02.YoutubeのURLリストからスクリプトを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "01で作成したURLリストを読み込む\n",
    "'''\n",
    "video_df = pd.read_csv('video_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "スクリプトを順番に読み込む\n",
    "* １ファイルあたり２秒程度\n",
    "* add_video_info=Trueとする場合は、pytubeをインストールする必要がある\n",
    "'''\n",
    "from tqdm import tqdm\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "documents = []\n",
    "for _, row in tqdm(video_df.iterrows(), total=video_df.shape[0]):\n",
    "    url=f'https://www.youtube.com/watch?v={row[\"video_id\"]}'\n",
    "    loader = YoutubeLoader.from_youtube_url(url, add_video_info=True, language='ja')\n",
    "    docs = loader.load()\n",
    "    documents.extend(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#メタデータには以下のような情報が含まれています\n",
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 03.キーワード検索を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.retrievers import  BaseRetriever\n",
    "\n",
    "class MultiKeywordRetriever(BaseRetriever):\n",
    "    docs: List[Document]\n",
    "    k: int = 5\n",
    "\n",
    "    def _get_relevant_documents(self, keywords: List[str]) -> List[Document]:\n",
    "        keywords_counts = []\n",
    "        for idx, doc in enumerate(self.docs):\n",
    "            keywords_count = {k: doc.page_content.count(k) for k in keywords}\n",
    "            keywords_count['min_count'] = min(keywords_count.values())  \n",
    "            keywords_count['idx'] = idx\n",
    "            keywords_counts.append(keywords_count)\n",
    "\n",
    "        keywords_counts = [dic for dic in keywords_counts if dic['min_count'] > 0]\n",
    "        keywords_counts = sorted(keywords_counts, key=lambda x: x['min_count'], reverse=True)\n",
    "        keywords_counts = keywords_counts[:self.k]\n",
    "\n",
    "        relevant_documents = [self.docs[dic['idx']] for dic in keywords_counts]\n",
    "        return relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ドガとマネに言及している動画\n",
    "'''\n",
    "keywords = ['ドガ','マネ']\n",
    "retriever = MultiKeywordRetriever(docs=documents,k=20)\n",
    "retriever.invoke(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ドラえもんに言及している動画\n",
    "'''\n",
    "keywords = ['ドラえもん']\n",
    "retriever = MultiKeywordRetriever(docs=documents,k=20)\n",
    "retriever.invoke(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 04.クエリからキーワードを生成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Search(BaseModel):\n",
    "    keywords: List[str] = Field(description=\"キーワード検索で使用するキーワード\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "system = \"\"\"あなたはユーザーの質問から固有名詞のキーワードを抽出するエキスパートです。\n",
    "例えば「ドガとマネの絵画について教えて下さい」という質問が来たら、[\"ドガ\", \"マネ\"]というキーワードを抽出します。\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        # MessagesPlaceholder(\"examples\", optional=True),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(Search)\n",
    "search_chain = (    \n",
    "    {\"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | structured_llm\n",
    ")\n",
    "res = search_chain.invoke('ドラえもんについて何が言及されていますか？')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret_docs = retriever.invoke(res.keywords)\n",
    "ret_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "for d in ret_docs:\n",
    "    pprint(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 05.文書から情報を抽出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"以下の質問についてドキュメントをもとに回答してください。\n",
    "ただしドキュメントはYoutubeの音声を文字起こししたもののため、不明瞭な文章の可能性があります。\n",
    "そのため、回答には注意してください。\n",
    "\n",
    "ドキュメント:{texts}\n",
    "\n",
    "質問:{question}\n",
    "\n",
    "回答:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = prompt_template,\n",
    "    input_variables=[\"texts\", \"question\"],\n",
    ")\n",
    "answer_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = answer_chain.invoke({\n",
    "    'texts':[doc.page_content for doc in ret_docs],\n",
    "    'question':'ドラえもんについて何が言及されていますか？'\n",
    "})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 06.これまでのをまとめて質問"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '「猫」についての言及をまとめて？' \n",
    "res = search_chain.invoke(question)\n",
    "print(res)\n",
    "ret_docs = retriever.invoke(res.keywords)\n",
    "print(ret_docs)\n",
    "res = answer_chain.invoke({\n",
    "    'texts':ret_docs[0].page_content,\n",
    "    'question':question,\n",
    "})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
